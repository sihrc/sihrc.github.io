<h2> Text Mining Mini Project </h2>

<blockquote>
nmohamed/text_mining.py
</blockquote>
<h3> Great Job! I have a few comments about some parts of your code below, but none were critical enough to really affect your grade. You have a few problems with ambiguity in your code but you made up for it through tests (not really only in points). </h3>

<pre><code class="language-python">
"""
    Nora Mohamed
    ~*2015 FEB*~

    Gets text and performs Markov analysis.
"""

import random

def get_prefixes(text, prefix):
    """ Gets prefixes depending on number of prefixes input to function and returns them
        text: Text to be made into prefixes
        prefix: Number of words per prefix

        >>> get_prefixes("Hello my friend Sal!", 2)
        ['Hello my ', 'my friend ', 'friend Sal! ', 'Sal! ']
    """
    words = text.split()
    if prefix == 1:
        return words
    group = []
    group2 = []
</code></pre>
<br>
<h4> Why do you have group and group2? Maybe a better naming convention or add a comment saying what they are.</h4>
</br>
<pre><code class="language-python">
    wordspace = ""

    for i in range(len(words) - 1):
        group.append(words[i:i + prefix])
    for element in group:
        for x in range(len(element)):
            wordspace += element[x]
            if x != len(element):
                wordspace += " "
        group2.append(wordspace)
        wordspace = ""
    group2.append(words[-1] + " ")
    return group2

def get_first_words(groups, prefix):
    """ Gets first word in sentences and returns a list of them
    """
    first = [groups[0]]
    for index in range(len(groups)):
        # if punctuation is in word, then add next word to first word
        if groups[-1] == groups[index]:
            break
        if groups[index][-1] in {".", "!", "?"}: #for prefix = 1
            first.append(groups[index+1])
        elif groups[index][-2:] in {".\"", "!\"", "?\"", ".\'", "?\'", "!\'"}:
        </code></pre>
<br>
<h4> Is there a reason why you're using a set here? They take longer to make than lists. </h4>
</br>
<pre><code class="language-python">
            first.append(groups[index+1])

        if groups[index][-2:] in {". ", "! ", "? ", "\" "}: #for prefix >1
            if index == len(groups)-prefix:
                break
            else:
                first.append(groups[index+prefix])
    return first

def create_dictionary(groups, prefix):
    """ Creates dictionary that maps prefixes to various suffixes

        groups: groups to be put into a dictionary
        prefix: # of words in each prefix
        returns: dictionary of words; dictionary of first words

    >>> create_dictionary(get_prefixes("Hello Nora my name is Nora too!", 1), 1)
    {'name': ['is'], 'too!': [], 'is': ['Nora'], 'Nora': ['my', 'too!'], 'my': ['name'], 'Hello': ['Nora']}

    >>> create_dictionary(get_prefixes("Hello Nora my name is Nora too!", 2), 2)
    {'Nora my ': ['name is '], 'is Nora ': ['too! '], 'my name ': ['is Nora '], 'name is ': ['Nora too! '], 'too! ': [], 'Nora too! ': [], 'Hello Nora ': ['my name ']}
    """
    w = {}
    </code></pre>
<br>
<h4> That variable name though. </h4>
</br>
<pre><code class="language-python">
    for x in range(len(groups)):
        w[groups[x]] = []
    for x in range(len(groups)):
        if x == len(groups)-prefix:
            break
        w[groups[x]].append(groups[x+prefix])
    return w

def read_file(file_name):
    """ Reads file data and returns lines in list form. Cleans up text by removing
        '\n' values
    """
    lines = []
    with open (file_name, "r") as myfile:
        data = myfile.readlines()
    for element in data:
        if element == "\n":
            pass
        else:
            lines.append(element.strip())
    return lines

def markov_creation(dictionary, length, prefix, first):
    """ Takes a dictionary and starts the sentence with a random word. Then adds likely
        suffix until sentence reaches end (punctuation) or len prefixes is reached

        words: dictionary with prefixes/suffixes
        len: number of prefixes max per sentence
        returns: sentence
    """
    sentence = random.choice(dictionary.keys())
    if first != []:
        sentence = random.choice(first)
    last_word = sentence
    if prefix == 1:
        sentence += " "

    for x in range(length-1):
        if dictionary[last_word] == []:
            break
        else:
            new_word = random.choice(dictionary[last_word])
            if prefix == 1:
                sentence += new_word + " "
            else:
                sentence += new_word
            if new_word[-1] in {".", "!", "?", "\""} or new_word.count(". ") + \
                                    new_word.count("? ") + new_word.count("! ") + \
                                    new_word.count("\" ") != 0:
                break
            last_word = new_word
    print sentence
    </code></pre>
<br>
<h4> What. Why print? You should return and only print in your if __name__ == "__main__" statement. In case someone wants to use this as a library and wants the results. </h4>
</br>
<pre><code class="language-python">


def do_everything(file_name, prefix = 1, length = 20, start_with_first = True):
</code></pre>
<br>
<h4> Hahahahaha. At least call it main or something. </h4>
</br>
<pre><code class="language-python">
    """ Does what premise of this code is.
    """
    add_words = {}
    words = {}
    first = []
    lines = read_file(file_name)

    for index in range(len(lines)):
        #get words
        groups = get_prefixes(lines[index], prefix)
        #create dictionary
        add_words = create_dictionary(groups, prefix)
        for key, value in add_words.iteritems():
            words.setdefault(key, []).extend(value)
        #get first word of sentence if True
        if start_with_first == True:
            first2 = get_first_words(groups, prefix)
            for element in first2:
                first.append(element)
    #make sentence!
    markov_creation(words, length, prefix, first)

if __name__ == '__main__':
    import doctest
    # doctest.testmod()

    do_everything("buzzfeed_titles.txt", 1, 50, True)
</code></pre>

<pre> <code class="language-python">
"""
      Nora Mohamed
      ~*2015 FEB*~
      Goes to BuzzFeed and puts article titles into .txt
"""

from pattern.web import *

def get_buzzfeed_titles(url):
      """ Gets buzzfeed article titles and puts them into a text file or string
            url: List of buzzfeed URLs that
            return: string of buzzfeed article titles
      """
      HTML = URL(url).download()
      index = 0
      title = ""
      while index != -1:
            index = HTML.find("rel:gt_act='post/title' >\n")
            if index == -1:
                  break
            HTML = HTML[index + 34:]
            title += HTML[0:HTML.find("      </a>")]
      return title

titles = ""
buzzfeed = ["http://www.buzzfeed.com/buzz", "http://www.buzzfeed.com/news",
            "http://www.buzzfeed.com/entertainment", "http://www.buzzfeed.com/quizzes"]
for page in buzzfeed:
      titles += get_buzzfeed_titles(page)
text_file = open("buzzfeed_titles.txt", "w")
text_file.write(titles)
text_file.close()
</code></pre>
